{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V7FSxm9kpI9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8f07656-ef42-45b5-b55f-a414ba768057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.16.tar.gz (50.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (4.15.0)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.6/329.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl size=4503265 sha256=e1b5399218f5c10564778209b4df6207b5997143706c97c1fbc310b9cf4c98a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/82/ab/8784ee3fb99ddb07fd36a679ddbe63122cc07718f6c1eb3be8\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: pypdf, numpy, diskcache, llama-cpp-python, faiss-cpu\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diskcache-5.6.3 faiss-cpu-1.13.2 llama-cpp-python-0.3.16 numpy-2.4.0 pypdf-6.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "3644c136658d40cd97e3498f7bf34563"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U \\\n",
        "  llama-cpp-python \\\n",
        "  sentence-transformers \\\n",
        "  faiss-cpu \\\n",
        "  pypdf \\\n",
        "  numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91tvFQ6iJ9f6",
        "outputId": "6a2a3346-8b7b-4efe-c485-474ef640306e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Buat folder di drive, lalu import model yang sudah didownload ke folder drive, next running tinggal mount saja"
      ],
      "metadata": {
        "id": "BrcP0nRcKccR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/LLM_Models\n",
        "!wget -O /content/drive/MyDrive/LLM_Models/Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf \\\n",
        "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-sJLVszKFSh",
        "outputId": "cbbf7f0e-60ae-4779-aee3-adf39eacf9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-03 05:28:57--  https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.17, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/681e1d718072a433272923b1/85cd8c98aac4976b402a77049f8e6808e8209f60fa833d2e0fe9cc5406144bcf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260103T052857Z&X-Amz-Expires=3600&X-Amz-Signature=2481b80e4c9071a2a6cfd1a31742952cecc83ae25c29c3cd5c97d28ce94ec2f0&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf%3B+filename%3D%22cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf%22%3B&x-id=GetObject&Expires=1767421737&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NzQyMTczN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODFlMWQ3MTgwNzJhNDMzMjcyOTIzYjEvODVjZDhjOThhYWM0OTc2YjQwMmE3NzA0OWY4ZTY4MDhlODIwOWY2MGZhODMzZDJlMGZlOWNjNTQwNjE0NGJjZioifV19&Signature=dOT41KAvp34irrgD9976ATrSMXaFfL-jwqSg39-Ff03oUctsw-X-Bqr-zqDn9lOQHq777x5rK9iuf14XaAMFh8Zt0g2qmCuja3XyK1Jli1pvoyOZ4mwEDMC%7EJ6MqbdRf6duxAFtmU19t-8ViWjKpkhdTiLK96G7QDx7thE-nIhI0A96Y0V2daYAQKf-nZFrf5cKi7KGvFvD8Z3%7EqGqoGXHILePq9mkPLqEMkF9ju1ess5AmrdoyrMhOYXlrxndhKpgKJ%7EEP6xhlSwF06APyQHo4tXAP0o5IwsrbGWMiQ-crdzJD4TLVM1bIs2p3MO15-ZpB58CQfqNnKyJC9QeL3sw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2026-01-03 05:28:57--  https://cas-bridge.xethub.hf.co/xet-bridge-us/681e1d718072a433272923b1/85cd8c98aac4976b402a77049f8e6808e8209f60fa833d2e0fe9cc5406144bcf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260103T052857Z&X-Amz-Expires=3600&X-Amz-Signature=2481b80e4c9071a2a6cfd1a31742952cecc83ae25c29c3cd5c97d28ce94ec2f0&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf%3B+filename%3D%22cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf%22%3B&x-id=GetObject&Expires=1767421737&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NzQyMTczN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODFlMWQ3MTgwNzJhNDMzMjcyOTIzYjEvODVjZDhjOThhYWM0OTc2YjQwMmE3NzA0OWY4ZTY4MDhlODIwOWY2MGZhODMzZDJlMGZlOWNjNTQwNjE0NGJjZioifV19&Signature=dOT41KAvp34irrgD9976ATrSMXaFfL-jwqSg39-Ff03oUctsw-X-Bqr-zqDn9lOQHq777x5rK9iuf14XaAMFh8Zt0g2qmCuja3XyK1Jli1pvoyOZ4mwEDMC%7EJ6MqbdRf6duxAFtmU19t-8ViWjKpkhdTiLK96G7QDx7thE-nIhI0A96Y0V2daYAQKf-nZFrf5cKi7KGvFvD8Z3%7EqGqoGXHILePq9mkPLqEMkF9ju1ess5AmrdoyrMhOYXlrxndhKpgKJ%7EEP6xhlSwF06APyQHo4tXAP0o5IwsrbGWMiQ-crdzJD4TLVM1bIs2p3MO15-ZpB58CQfqNnKyJC9QeL3sw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 3.168.132.96, 3.168.132.31, 3.168.132.4, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|3.168.132.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8890325376 (8.3G)\n",
            "Saving to: ‘/content/drive/MyDrive/LLM_Models/Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]   8.28G  61.6MB/s    in 2m 18s  \n",
            "\n",
            "2026-01-03 05:31:15 (61.6 MB/s) - ‘/content/drive/MyDrive/LLM_Models/Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf’ saved [8890325376/8890325376]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wapOuLtR2uND",
        "outputId": "dca9d33e-8315-42c6-c13c-6c55e62fb7d8"
      },
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=\"/content/drive/MyDrive/LLM_Models/Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf\",\n",
        "    n_ctx=4096,\n",
        "    n_gpu_layers=10,  # Changed to 10 as requested\n",
        "    verbose=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnaDw4awQYZZ",
        "outputId": "c25be527-7b5e-462d-fa18-6a25c962ff46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20251107 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-5.2.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.2.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def load_pdf(path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def chunk_text(text, chunk_size=500, overlap=100):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        chunks.append(text[start:start+chunk_size])\n",
        "        start += chunk_size - overlap\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "6N6wwnlnLob4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Now load_pdf will use '/content/E-Book.pdf' as passed.\n",
        "# Ensure '/content/E-Book.pdf' is a valid PDF, or change the path here.\n",
        "text = load_pdf(\"/content/BUKU AI SMK Kelas 12 Semester 1.pdf\")\n",
        "chunks = chunk_text(text)\n",
        "\n",
        "print(\"TEXT LENGTH:\", len(text))\n",
        "print(\"TOTAL CHUNKS:\", len(chunks))\n",
        "print(\"CHUNKS SAMPLE:\", chunks[:2])\n",
        "\n",
        "\n",
        "embeddings = embedder.encode(chunks)\n",
        "embeddings = np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"✅ Vector DB siap | Total chunks: {len(chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSN3YyUnNPjZ",
        "outputId": "7b5ff99e-566a-47d1-8202-b01ff7278037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXT LENGTH: 250445\n",
            "TOTAL CHUNKS: 627\n",
            "CHUNKS SAMPLE: ['Kelas 12 Semester 1\\nFine-Tuning & Aplikasi AI di Industri\\nAnas Nasrulloh\\nOnno W. Purbo\\nInstitut Teknologi Tangerang Selatan (ITTS)\\nOnnoCenter\\n2025\\nAI SMK Kelas 12 Semester 1 2\\nLisensi & Catatan Karya\\nKarya ini dilisensikan di bawah lisensi Creative Commons Attribution-ShareAlike 4.0\\nInternational (CC BY-SA 4.0).\\nArtinya, siapa pun bebas untuk menggunakan, menyalin, membagikan, dan\\nmengadaptasi materi ini, dengan syarat:\\n● Memberikan atribusi yang sesuai (menyebut sumber asli),\\n● Menyertakan lise', 'eri ini, dengan syarat:\\n● Memberikan atribusi yang sesuai (menyebut sumber asli),\\n● Menyertakan lisensi yang sama jika dimodifikasi atau dikembangkan lebih lanjut.\\nLihat detail lisensi di sini https://creativecommons.org/licenses/by-nd/4.0/legalcode.id\\nDesain Cover: Irwan Siswanto\\nDisclaimer\\nMateri pembelajaran ini dibuat dengan dana swadaya masyarakat Indonesia dan\\nkontribusi sukarela dari para dosen di Institut Teknologi Tangerang Selatan (ITTS).\\nKarya ini didistribusikan secara bebas untuk me']\n",
            "✅ Vector DB siap | Total chunks: 627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, k=3):\n",
        "    q_emb = embedder.encode([query]).astype(\"float32\")\n",
        "    _, idx = index.search(q_emb, k)\n",
        "    return [chunks[i] for i in idx[0]]\n"
      ],
      "metadata": {
        "id": "zivjc2UBSCQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_rag(question):\n",
        "    contexts = retrieve(question)\n",
        "    context_text = \"\\n\\n\".join(contexts)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "[INST]\n",
        "Kamu adalah asisten AI yang menjawab HANYA berdasarkan konteks.\n",
        "\n",
        "KONTEKS:\n",
        "{context_text}\n",
        "\n",
        "PERTANYAAN:\n",
        "{question}\n",
        "\n",
        "Jawab dengan bahasa Indonesia yang jelas, ringkas, dan faktual.\n",
        "Jika jawaban tidak ada di konteks, katakan \"Informasi tidak ditemukan di dokumen\".\n",
        "[/INST]\n",
        "\"\"\"\n",
        "\n",
        "    output = llm(\n",
        "        prompt,\n",
        "        max_tokens=300,\n",
        "        temperature=0.2,\n",
        "        stop=[\"</s>\"]\n",
        "    )\n",
        "\n",
        "    return output[\"choices\"][0][\"text\"]\n"
      ],
      "metadata": {
        "id": "WSdzn7ybSVFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_question = \"Buku ini tentang apa\"\n",
        "answer = ask_rag(test_question)\n",
        "print(f\"Pertanyaan: {test_question}\")\n",
        "print(f\"Jawaban Bot: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJtvkahLZYdR",
        "outputId": "3aa53cc7-2407-4d1e-db7d-c5fe3bb4f126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pertanyaan: Buku ini tentang apa\n",
            "Jawaban Bot: Buku ini tentang penggunaan AI dalam berbagai konteks, termasuk pabrik, bisnis, dan pendidikan. Di pabrik, AI digunakan untuk mengangkat besi, mendeteksi kerusakan mesin, mengatur jadwal produksi, dan menghemat energi listrik. Di dunia bisnis, AI dapat menebak selera pelanggan dan menyarankan produk yang cocok berdasarkan riwayat belanja. Di sekolah, AI dapat membantu siswa belajar dengan cara tambahkan data dan ulangi fine-tuning. Buku juga mencakup topik tentang pembuatan chatbot sekolah dan cara menilai keefektifannya dalam menjawab pertanyaan siswa.\n",
            "\n",
            "Informasi tidak ditemukan di dokumen tentang detail lebih lanjut mengenai konten buku selain yang telah dijelaskan di konteks.\n"
          ]
        }
      ]
    }
  ]
}